This repository is a SWI-Prolog application (portage-ng).

## Description 

The application reads Gentoo ebuild md5-cache files from a Gentoo portage tree repository into SWI-Prolog cache predicates. 
See cache.pl for the datastructure. The actual data is contained in kb.raw (which is qcompiled into kb.qlf).

- `Source/repository.pl`: enables controlling of Portage tree (syncing, loading, saving facts)
- `Source/knowledgebase.pl`: different repositories register themselves with the knowledge base. 
- `Source/cache.pl`: the prolog cache data structure 
- `Source/eapi.pl`: a Prolog DCG grammar to read md5-cache syntax
- `Source/rules.pl`: domain specific (Gentoo) specific rules handling dependencies, interpreting use flags, PDEPEND hooks, etc.
- `Source/vdb.pl`: a repository containing information about installed ebuilds
- `Source/sampler.pl`: performance sampling and instrumentation (hook perf, test_stats counters, ctx_union sampling)
- `Source/subprocess.pl`: generic external process spawning and dns-sd interface
- `Source/interface.pl`: CLI option parsing, TTY init, request dispatching
- `Source/cluster.pl`: high-level orchestration for distributed proving across workers
- `Source/worker.pl`: compute node for distributed proving (polls server for jobs)
- `Source/server.pl`: Pengine HTTP server + job/result queues for distributed proving


## Architecture (mental model)
Pipeline (standalone):

- reader/parser build cache facts using eapi grammar
- prover makes proofs (ProofAVL, ModelAVL, Constraints, TriggersAVL) using rules 
- planner does fast wave planning for acyclic portion of graph represented by rules in proof and returns a remainder
- scheduler post-processes remainder: SCC (Kosaraju) and merge-sets for :run SCCs
- printer renders plan + assumptions & warnings

Key files:
- `Source/prover.pl`: inductive proof search; cycles become prover cycle-break assumptions (`assumed(rule(Lit))` in proof, `assumed(Lit)` in model).
- `Source/rules.pl`: domain rules; domain assumptions appear as `rule(assumed(X), [])` and show as “Domain assumptions”.
- `Source/planner.pl`: wave planner; returns (Plan, RemainderRules).
- `Source/scheduler.pl`: SCC/merge-set scheduling for remainder; acts only on :run SCCs.
- `Source/printer.pl`: output + warnings; distinguishes domain assumptions vs prover cycle-breaks. `prove_plan/5` is the standard entry point (always uses delayed triggers and PDEPEND).
- `Source/version.pl`: version domain model (`version_domain(Slots, Bounds)`), domain meet/intersection, consistency checks.

Version representation:
- Versions are stored as `version/7` compound terms: `version(NumsNorm, Alpha, SuffixRank, SuffixNum, SuffixRest, Rev, Full)`.
- Empty/absent versions use the atom `version_none`.
- Comparison uses standard `compare/3` directly on the compound term (no runtime key conversion).

PDEPEND handling:
- PDEPEND is always enabled (unconditionally asserted in `preference:init`).
- There is no `--pdepend` CLI flag. Do NOT add `preference:flag(pdepend)` guards.
- PDEPEND deps are resolved single-pass inside the prover via `rules:literal_hook/4`.

Assumption taxonomy (do not mix these up):

- Domain assumptions (rules-level): proof key `rule(assumed(X))`
- Prover cycle-break assumptions: proof key `assumed(rule(X))`

## Learned constraint refinement

The prover offers a generic learned constraint store that persists across
proof retries (managed by `with_cn_domain_reprove_state`):

- `prover:learn(Literal, Constraint, Added)` — store/merge a constraint
- `prover:learned(Literal, Constraint)` — look up a learned constraint
- Merge semantics: `feature_unification:val_hook` (e.g., domain intersection)
- Literal format: `cn_domain(Category, Name, Slot)` for version domains

Rules uses this store in three ways:
1. **Candidate narrowing**: `grouped_dep_effective_domain` intersects the
   local+context domain with any learned domain (`apply_learned_domain`).
2. **Conflict learning**: constraint guards learn the domain when a conflict
   is detected (alongside the existing reject-based reprove mechanism).
3. **Parent narrowing**: `maybe_learn_parent_narrowing` learns to exclude the
   parent version when a child dep can't be satisfied (wrong-level fix).

Inspired by Zeller's feature logic (incremental domain narrowing) and
Vermeir/Van Nieuwenborgh's ordered logic programs (priority-based conflict
resolution). See `Documentation/resolver-comparison.md`.

### Testing learned constraints
When testing changes to the learned constraint mechanism, ALWAYS verify:
1. Exit code (0 = no assumptions, 1 = cycle breaks only, 2 = domain assumptions)
2. "Total: N actions" line present (proof completed, not crashed)
3. Count of "non-existent" lines
4. No "Unknown message" or escaping exceptions in output
5. Runtime (should be < 10 seconds for single targets)


## Configuration

### Portage tree locations
- `Source/Config/mac-pro.pl`: contains the specific configuration (location of repository, md5-cache, vdb pkg installation data)

### Graph location
- `Source/config.pl`: graph_directory/2 holds the location of the graph directory that contains .emerge files (traditional gentoo emerge output for a given package). 

### Configuration 
- `Source/config.pl`: configuration file with various configuration settings



## How to run (IMPORTANT)
- Do NOT run ad-hoc `swipl -g "..."` snippets; they often miss required operator defs, libraries, and module load order.
- Always launch via the project wrapper (project root):
  - `./Source/Scripts/portage-ng-dev --mode standalone --pretend <target>`
  - `./Source/Scripts/portage-ng-dev --mode standalone --shell`
  - Non-interactive / CI-style: `./Source/Scripts/portage-ng-dev --mode standalone --ci --pretend <target>`
    Exit codes:
      - 0 = no assumptions
      - 1 = only prover cycle-break assumptions
      - 2 = any domain assumptions (e.g. missing/non-existent deps)

- For resolver/debug target runs in this workflow, always include `--pretend` to avoid
  mutating local state (for example `Source/Sets/world/*.local`).

### Preferred scripted workflow (here-doc “piping”)
For quick iteration and for reproducible debugging, prefer running a *scripted* Prolog session via `--shell` and a here-doc:

```sh
./Source/Scripts/portage-ng-dev --mode standalone --shell --time-limit 60 <<'PL'
prover:test_stats(portage).
% Any other queries you want:
% prover:test_stats_pkgs(portage, ['kde-apps'-'kde-apps-meta']).
halt.
PL
```

This keeps the full project load graph intact (same as interactive `--shell`), while letting you run multi-line “scripts” non-interactively.

The canonical load graph for standalone is in `portage-ng.pl`:
- `load_common_modules/0`
- `load_standalone_modules/0`

### Non-interactive / sandbox robustness
- Terminal size lookups must go through `config:printing_tty_size/2` (direct `tty_size/2` may throw in non-tty environments).
- Do NOT run `--sync` / repository syncing from inside the sandbox. The user will run `--sync` externally when needed.
- Do NOT create `metadata/md5-cache/*` manually. `--sync` (egencache/md5-cache generation) produces those automatically.
- Do NOT run `--graph` / repository graphing from inside the sandbox. The user will run `--graph` externally when needed.

## Performance/engineering notes
- Proof/Model/Triggers are assoc/AVL-based; avoid repeated full traversals when possible.
- Query performance uses `goal_expansion/2` macros in `Source/query.pl`.

## Development flow
- We use a git workflow. 
- Start development always with clean committed state  
- When development is done, ask user to regenerate .merge files 
- Run compare analysis between merge and emerge files (see below) to detect regressions.
- Ask user for permission to commit.

## Compare merge vs emerge plans
-  Merge vs Emerge files:
  - `*.merge`: files in the graph directory for a given repository contain output of portage-ng
  - `*.emerge`: files in the graph directory for a given repository contain output of gentoo emerge

- The configuration on both the Gentoo system and portage-ng is identical (same portage snapshot, same vdb pkg data, same config

- Full run:
  - `python3 -u Source/Scripts/compare-merge-emerge.py --root /Volumes/Storage/Graph/portage --full-lists --out Reports/compare-<tag>.json`

- Targeted run:
  - `python3 -u Source/Scripts/compare-merge-emerge.py --root /Volumes/Storage/Graph/portage --target-regex '^pkg-ver$' --full-lists --out Reports/compare-<tag>.json`

- Useful output fields:
  - `aggregate_counts` (missing/extra/version/use/action totals)
  - `aggregate_assumptions` (domain assumptions / blockers / cycle breaks)
  - `top_missing_cpn`, `top_extra_cpn`, `top_domain_assumptions`

- When comparing provide output in a table;
  - Columns: comparing previous compare data vs currect compare data (columns)
  - Rows: % vs portage merge_ok for CN, CN+V, CN+V+U, #blockers, #cycle breaks, #domain assumptions

- Canonical metric formula for `% vs portage merge_ok` rows (use this exact formula):
  - Filter to `emerge_ok == true` pairs only.
  - For each pair define:
    - `e = counts.emerge_pkgs`
    - `m = counts.missing_in_merge`
    - `x = counts.extra_in_merge`
    - `v = counts.version_mismatches`
    - `u = counts.use_mismatches` (not `use_mismatches_common`)
    - `i_cnv = e - m`
    - `u_cnv = e + x`
  - Aggregate by summing across all `emerge_ok` pairs:
    - `inter_cnv = Σ(i_cnv)`, `union_cnv = Σ(u_cnv)`
    - `inter_cn  = Σ(i_cnv + v)`, `union_cn  = Σ(u_cnv - v)`
    - `inter_cnvu = Σ(i_cnv - u)`, `union_cnvu = Σ(u_cnv + u)`
  - Final percentages:
    - `CN      = 100 * inter_cn / union_cn`
    - `CN+V    = 100 * inter_cnv / union_cnv`
    - `CN+V+U  = 100 * inter_cnvu / union_cnvu`
  - Count rows in the same table are also `emerge_ok`-only sums:
    - `#blockers = Σ assumptions.blockers`
    - `#cycle breaks = Σ assumptions.cycle_breaks`
    - `#domain assumptions = Σ assumptions.domain_assumptions`

- The table output is used to determine regressions

## Compare tooling (authoritative paths + usage)
- Keep compare scripts in `Source/Scripts/`:
  - `Source/Scripts/compare-merge-emerge.py`
  - `Source/Scripts/compare-prover-failset.py`
- Do not create ad-hoc compare scripts outside `Source/Scripts/`.

### Compare prover fail-sets
- Compare two `prover:test(portage)` logs:
  - `python3 Source/Scripts/compare-prover-failset.py --baseline <baseline.log> --candidate <candidate.log> --out Reports/prover_failset_compare.json`

## Compare to portage source code
- The portage source code can be found in /Volumes/Disk\ 2/Git/portage on this system.